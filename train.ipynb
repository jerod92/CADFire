{
 "nbformat": 4,
 "nbformat_minor": 4,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CADFire Training Notebook\n",
    "\n",
    "Training notebook for vast.ai GPU instances.\n",
    "\n",
    "## Four-Phase Pipeline\n",
    "\n",
    "| Phase | Cell | Description | Typical time |\n",
    "|-------|------|-------------|-------------|\n",
    "| **1** | 3a | **Tool Classifier** — text → tool, no vision. Text encoder + fusion + tool head trained from scratch via cross-entropy. | ~1 min |\n",
    "| **2** | 3b | **Semantic Cursor** — vision + text → tool + cursor, single-step, 11 task types. *All* parameters unfrozen (incl. text encoder) so the model links object names to visual appearances. | ~10–30 min |\n",
    "| **3** | 3c | **Teacher Forcing** — vision + text → tool + cursor, 2–9-step trajectories. Oracle advances the env at each step; loss computed per step. Bridges single-step Phase 2 and sparse-reward Phase 4. | ~20–60 min |\n",
    "| — | 3d | **Diagnostics** — oracle + free-run GIFs to evaluate polygon-tracing capability before RL. | ~1 min |\n",
    "| **4** | 3e | **PPO RL** — full agent, curriculum learning. Resumes from Phase-3 checkpoint. | hours |\n",
    "\n",
    "> **Tip**: Phases 1–3 only need to run once per fresh instance.  \n",
    "> After a pretrained checkpoint is saved, subsequent RL runs resume from it automatically.\n",
    ">\n",
    "> Weights accumulate across phases: passing `agent=agent` between cells re-uses in-memory weights;  \n",
    "> omitting it loads from the checkpoint file on disk."
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup (run once per instance)\n",
    "# pillow is required for diagnostic GIF generation (Phase 3d)\n",
    "!pip install -q torch numpy matplotlib pillow\n",
    "\n",
    "import sys, os\n",
    "sys.path.insert(0, os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Verify environment\n",
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "from cadfire.tasks.registry import TaskRegistry\n",
    "TaskRegistry.discover()\n",
    "print(f\"\\nRegistered tasks ({TaskRegistry.count()}): {TaskRegistry.list_tasks()}\")\n",
    "\n",
    "from cadfire.utils.config import num_tools, tool_list\n",
    "print(f\"Tools ({num_tools()}): {tool_list()[:10]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3a: Phase 1 — Tool Classifier Pretraining\n",
    "#\n",
    "# Trains: text encoder + fusion bridge + tool head\n",
    "# Frozen:  vision encoder, cursor head (UNet decoder)\n",
    "# Loss:    cross-entropy over (prompt → tool_id) pairs\n",
    "#\n",
    "# Idempotent: loads any existing checkpoint first, trains on top of it.\n",
    "# Raise num_epochs to 50 for ~95%+ accuracy.\n",
    "\n",
    "from train import run_pretrain_tool\n",
    "\n",
    "agent = run_pretrain_tool(\n",
    "    num_epochs=30,        # ~1 min on GPU; raise to 50 for higher accuracy\n",
    "    lr=1e-3,\n",
    "    batch_size=64,\n",
    "    checkpoint_dir=\"checkpoints_1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3b: Phase 2 — Semantic Cursor Pretraining\n",
    "#\n",
    "# Trains:  ALL parameters (vision encoder, text encoder, fusion, tool head, cursor head)\n",
    "# Frozen:  nothing — text encoder intentionally unfrozen so the model learns to\n",
    "#          associate object names (\"hexagon\", \"circle\") with visual appearances.\n",
    "# Loss:    cross-entropy tool loss + MSE cursor loss (Gaussian blob targets)\n",
    "#\n",
    "# 11 one-step supervised task types:\n",
    "#   SELECT, MULTISELECT, ERASE, PAN (4 dirs), ZOOM_IN, ZOOM_OUT,\n",
    "#   HATCH, POLYLINE trace-next, COPY, MOVE, ROTATE\n",
    "#\n",
    "# Loads Phase-1 weights from checkpoint if `agent` is not already in scope.\n",
    "\n",
    "from train import run_pretrain_semantic\n",
    "\n",
    "agent = run_pretrain_semantic(\n",
    "    agent=globals().get(\"agent\"),   # reuse Phase-1 agent if it ran above\n",
    "    num_samples=20_000,   # generated samples per epoch; raise to 50_000 for better coverage\n",
    "    num_epochs=20,\n",
    "    lr=3e-4,\n",
    "    batch_size=32,        # keep small — images are 256×256×19\n",
    "    sigma=12.0,           # Gaussian blob radius in pixels\n",
    "    cursor_weight=1.0,    # relative weight of cursor loss vs tool loss\n",
    "    num_workers=0,        # set to 4 on multi-core instances for faster dataloading\n",
    "    checkpoint_dir=\"checkpoints_1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3c: Phase 3 — Teacher-Forced Multi-Step Pretraining\n",
    "#\n",
    "# Trains:  ALL parameters (same as Phase 2)\n",
    "# Method:  at each trajectory step the ORACLE action is executed in the real\n",
    "#          environment (teacher forcing); agent loss computed per-step.\n",
    "# Loss:    cross-entropy tool loss + MSE cursor loss, summed over trajectory steps\n",
    "#\n",
    "# Trajectory mix (default):\n",
    "#   70% polygon-trace  (4–9 POLYLINE steps + CONFIRM)\n",
    "#   30% 2-step chains  (select→erase, select→rotate, select→copy)\n",
    "#\n",
    "# Loads Phase-2 weights from checkpoint if `agent` is not already in scope.\n",
    "\n",
    "from train import run_pretrain_teacher\n",
    "\n",
    "agent = run_pretrain_teacher(\n",
    "    agent=globals().get(\"agent\"),    # reuse Phase-2 agent if it ran above\n",
    "    num_trajectories=5_000,  # trajectories generated per epoch\n",
    "    num_epochs=15,\n",
    "    lr=1e-4,\n",
    "    sigma=12.0,              # Gaussian blob radius in pixels\n",
    "    cursor_weight=1.5,       # cursor loss weighted higher — sequencing is hard\n",
    "    polygon_ratio=0.7,       # fraction of polygon-trace trajectories\n",
    "    checkpoint_dir=\"checkpoints_1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3d: Post-Phase-3 Diagnostics — Polygon Tracing GIFs\n",
    "#\n",
    "# Produces two GIF types per episode inside diagnostics/:\n",
    "#   oracle_ep<N>.gif  — oracle-driven rollout with agent heatmap overlay\n",
    "#   free_ep<N>.gif    — fully autonomous agent rollout (no teacher forcing)\n",
    "#\n",
    "# Review the free_ep GIFs: if the agent traces polygons end-to-end without\n",
    "# oracle guidance it is ready for Phase 4 RL.\n",
    "# Requires: pillow  (installed in Cell 1)\n",
    "\n",
    "from train import run_diagnostics\n",
    "from pathlib import Path\n",
    "\n",
    "metrics = run_diagnostics(\n",
    "    agent=globals().get(\"agent\"),   # reuse Phase-3 agent if it ran above\n",
    "    n_episodes=6,\n",
    "    output_dir=\"diagnostics\",\n",
    "    fps=1.5,\n",
    "    checkpoint_dir=\"checkpoints_1\",\n",
    ")\n",
    "\n",
    "print(\"\\nGenerated GIFs:\")\n",
    "for p in sorted(Path(\"diagnostics\").glob(\"*.gif\")):\n",
    "    print(f\"  {p}\")\n",
    "\n",
    "if metrics:\n",
    "    print(f\"\\nFree-run mean reward  : {metrics.get('mean_free_reward', 0):.3f}\")\n",
    "    print(f\"Oracle mean reward    : {metrics.get('mean_oracle_reward', 0):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3e: Phase 4 — PPO RL Training\n",
    "#\n",
    "# Full agent training with curriculum learning.\n",
    "# Automatically loads from the Phase-3 checkpoint so all prior\n",
    "# supervised learning is preserved.\n",
    "#\n",
    "# Curriculum: difficulty cap starts at 2.0, grows every 5 000 steps.\n",
    "# Checkpoints saved to checkpoints_1/latest.pt and checkpoints_1/best.pt.\n",
    "\n",
    "from train import run_training\n",
    "\n",
    "metrics_history = []\n",
    "def collect_metrics(m):\n",
    "    metrics_history.append(m)\n",
    "\n",
    "trainer = run_training(\n",
    "    num_steps=100_000,     # total PPO environment steps\n",
    "    resume=True,           # auto-resume from checkpoints_1/latest.pt\n",
    "    device=None,           # auto-detect GPU\n",
    "    max_difficulty=None,   # curriculum default: starts at 2.0, grows every 5 000 steps\n",
    "    checkpoint_dir=\"checkpoints_1\",\n",
    "    callback=collect_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Plot training progress\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "diag_path = Path(\"checkpoints_1/diagnostics.json\")\n",
    "if diag_path.exists():\n",
    "    with open(diag_path) as f:\n",
    "        diag = json.load(f)\n",
    "    log = diag[\"training_log\"]\n",
    "\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 8))\n",
    "\n",
    "    steps = [e[\"step\"] for e in log]\n",
    "\n",
    "    axes[0, 0].plot(steps, [e.get(\"avg_reward\", 0) for e in log])\n",
    "    axes[0, 0].set_title(\"Average Reward\"); axes[0, 0].set_xlabel(\"Step\")\n",
    "\n",
    "    axes[0, 1].plot(steps, [e.get(\"policy_loss\", 0) for e in log])\n",
    "    axes[0, 1].set_title(\"Policy Loss\"); axes[0, 1].set_xlabel(\"Step\")\n",
    "\n",
    "    axes[0, 2].plot(steps, [e.get(\"difficulty\", 0) for e in log])\n",
    "    axes[0, 2].set_title(\"Curriculum Difficulty\"); axes[0, 2].set_xlabel(\"Step\")\n",
    "\n",
    "    axes[1, 0].plot(steps, [e.get(\"value_loss\", 0) for e in log])\n",
    "    axes[1, 0].set_title(\"Value Loss\"); axes[1, 0].set_xlabel(\"Step\")\n",
    "\n",
    "    axes[1, 1].plot(steps, [e.get(\"entropy\", 0) for e in log])\n",
    "    axes[1, 1].set_title(\"Entropy\"); axes[1, 1].set_xlabel(\"Step\")\n",
    "\n",
    "    axes[1, 2].plot(steps, [e.get(\"steps_per_second\", 0) for e in log])\n",
    "    axes[1, 2].set_title(\"Steps/sec\"); axes[1, 2].set_xlabel(\"Step\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"checkpoints_1/training_curves.png\", dpi=100)\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Total steps    : {diag['total_steps']}\")\n",
    "    print(f\"Total episodes : {diag['total_episodes']}\")\n",
    "    print(f\"Best reward    : {diag['best_reward']:.4f}\")\n",
    "else:\n",
    "    print(\"No diagnostics found yet. Run Phase 4 (Cell 3e) first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Visualize agent behavior on a specific task\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from cadfire.env.cad_env import CADEnv\n",
    "from cadfire.model.cad_agent import CADAgent\n",
    "from cadfire.renderer.rasterizer import Renderer\n",
    "from cadfire.tasks.registry import TaskRegistry\n",
    "from cadfire.utils.config import load_config\n",
    "\n",
    "config = load_config()\n",
    "env = CADEnv(config)\n",
    "agent_vis = CADAgent.load_checkpoint(\"checkpoints_1/best.pt\", config)\n",
    "agent_vis.eval()\n",
    "renderer = Renderer(config)\n",
    "\n",
    "# Pick a task — change task_name to explore other behaviours\n",
    "task = TaskRegistry.create(\"draw_circle\", seed=42)\n",
    "obs, info = env.reset(task=task)\n",
    "print(f\"Prompt: {info['prompt']}\")\n",
    "\n",
    "frames = [renderer.render_rgb_only(env.engine)]\n",
    "total_reward = 0\n",
    "\n",
    "for step in range(50):\n",
    "    obs_t = {\n",
    "        \"image\":    torch.tensor(obs[\"image\"]).unsqueeze(0),\n",
    "        \"text_ids\": torch.tensor(obs[\"text_ids\"], dtype=torch.long).unsqueeze(0),\n",
    "        \"state_vec\":torch.tensor(obs[\"state_vec\"]).unsqueeze(0),\n",
    "    }\n",
    "    action_info = agent_vis.act(obs_t, deterministic=True)\n",
    "    action = {\n",
    "        \"tool_id\": action_info[\"tool_id\"].item(),\n",
    "        \"cursor\":  action_info[\"cursor\"].cpu().numpy()[0],\n",
    "        \"param\":   action_info[\"param\"].item(),\n",
    "    }\n",
    "    obs, reward, term, trunc, info = env.step(action)\n",
    "    total_reward += reward\n",
    "    frames.append(renderer.render_rgb_only(env.engine))\n",
    "    if term or trunc:\n",
    "        break\n",
    "\n",
    "print(f\"Total reward: {total_reward:.3f}, Steps: {step + 1}\")\n",
    "\n",
    "# Show first, middle, and last frame\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "for ax, idx, title in zip(axes, [0, len(frames) // 2, -1], [\"Start\", \"Middle\", \"End\"]):\n",
    "    ax.imshow(frames[idx])\n",
    "    ax.set_title(title)\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Export a drawing to DXF\n",
    "from cadfire.export.dxf_writer import DXFWriter\n",
    "\n",
    "writer = DXFWriter()\n",
    "writer.write(env.engine, \"output.dxf\")\n",
    "print(\"Exported to output.dxf\")\n",
    "print(f\"Entities: {env.engine.entity_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Pull updates and continue training\n",
    "# After new tasks or config changes are pushed upstream:\n",
    "!git pull origin main\n",
    "\n",
    "# Reload config and re-discover tasks (handles new task files automatically)\n",
    "from cadfire.utils.config import reload\n",
    "reload()\n",
    "from cadfire.tasks.registry import TaskRegistry\n",
    "TaskRegistry.discover()\n",
    "print(f\"Tasks after update: {TaskRegistry.list_tasks()}\")\n",
    "\n",
    "# Continue Phase 4 — auto-resumes, handles tool-list growth seamlessly\n",
    "from train import run_training\n",
    "trainer = run_training(num_steps=50_000, resume=True, checkpoint_dir=\"checkpoints_1\")"
   ]
  }
 ]
}
