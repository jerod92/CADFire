{
 "nbformat": 4,
 "nbformat_minor": 4,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CADFire Training Notebook\n",
    "\n",
    "Interactive training notebook for vast.ai GPU instances.\n",
    "\n",
    "## Four-Phase Pipeline\n",
    "\n",
    "| Phase | Cell | What trains | Why | Typical time |\n",
    "|-------|------|-------------|-----|--------------|\n",
    "| **1** | 3a | Text encoder + fusion + tool head | Text → tool mapping, no vision | ~1 min |\n",
    "| **2** | 3b | All parameters (incl. text encoder) | Vision + text → tool + cursor, 20 task types, single-step | ~15–30 min |\n",
    "| **3** | 3c | All parameters | 2–9-step trajectories with oracle teacher forcing | ~30–60 min |\n",
    "| — | 3d | — | GIF diagnostics to evaluate polygon tracing before RL | ~1 min |\n",
    "| **4** | 3e | All parameters (PPO) | Curriculum RL, sparse rewards, exploration | hours |\n",
    "\n",
    "## Phase-2 Supervised Tasks (20 types)\n",
    "\n",
    "**Original 11:** SELECT · MULTISELECT · ERASE · PAN · ZOOM_IN · ZOOM_OUT · HATCH · POLYLINE-next-vertex · COPY · MOVE · ROTATE\n",
    "\n",
    "**New single-step:** SCALE · MIRROR · OFFSET\n",
    "\n",
    "**New multi-turn chat** *(prompt = `\"Draw a {shape} | <instruction>\"`)*:\n",
    "- `ScaleFromChatTask`       – *\"Draw a circle | make it smaller\"*  → SCALE\n",
    "- `MoveFromChatTask`        – *\"Draw a circle | move it right\"*    → MOVE + cursor at destination\n",
    "- `RotateFromChatTask`      – *\"Draw a circle | rotate it 90°\"*    → ROTATE\n",
    "- `EraseFromChatTask`       – *\"Draw a circle | delete it\"*        → ERASE\n",
    "- `ChangeColorFromChatTask` – *\"Draw a circle | change it to red\"* → COLOR_SET\n",
    "- `CopyFromChatTask`        – *\"Draw a circle | copy it to the right\"* → COPY + cursor at destination\n",
    "\n",
    "## Checkpoint Convention\n",
    "\n",
    "```\n",
    "checkpoints/\n",
    "  run_20260219_1400/          ← one directory per training run\n",
    "    latest.pt                 ← overwritten every save_interval steps\n",
    "    best.pt                   ← highest RL reward seen\n",
    "    phase1_final.pt           ← snapshot after Phase 1\n",
    "    phase2_final.pt           ← snapshot after Phase 2\n",
    "    phase3_final.pt           ← snapshot after Phase 3\n",
    "    diagnostics.json          ← PPO training log\n",
    "  run_20260220_0900/\n",
    "    ...\n",
    "```\n",
    "\n",
    "> **Tip**: Pass `RESUME_FROM` in Cell 2 to warm-start from a previous run."
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup (run once per instance)\n",
    "# pillow is required for diagnostic GIF generation (Cell 3d)\n",
    "!pip install -q torch numpy matplotlib pillow\n",
    "\n",
    "import sys, os\n",
    "sys.path.insert(0, os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Git pull + Run configuration\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Run this at the start of every session.\n",
    "# It pulls the latest code, names this training run, and sets up the\n",
    "# checkpoint directory.  All subsequent cells read CKPT_DIR automatically.\n",
    "\n",
    "import datetime, json, shutil, subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# ── Pull latest code ──────────────────────────────────────────────────────────\n",
    "result = subprocess.run([\"git\", \"pull\", \"origin\", \"main\"],\n",
    "                        capture_output=True, text=True)\n",
    "print(result.stdout.strip() or result.stderr.strip())\n",
    "\n",
    "# ── Run name ──────────────────────────────────────────────────────────────────\n",
    "# Override RUN_NAME with a memorable label, e.g. \"multiturn_v1\" or \"scale_fix\".\n",
    "# Default: timestamp so every run is uniquely tracked.\n",
    "RUN_NAME    = f\"run_{datetime.datetime.now().strftime('%Y%m%d_%H%M')}\"\n",
    "CKPT_DIR    = f\"checkpoints/{RUN_NAME}\"\n",
    "\n",
    "# ── Optional: warm-start from a previous run ──────────────────────────────────\n",
    "# Set to a previous CKPT_DIR to copy its checkpoints in as the starting point.\n",
    "# Leave as None to start fresh.\n",
    "RESUME_FROM = None   # e.g. \"checkpoints/run_20260219_1400\"\n",
    "\n",
    "# ── Create checkpoint directory ───────────────────────────────────────────────\n",
    "Path(CKPT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if RESUME_FROM and Path(RESUME_FROM).exists():\n",
    "    for pt in Path(RESUME_FROM).glob(\"*.pt\"):\n",
    "        shutil.copy(pt, Path(CKPT_DIR) / pt.name)\n",
    "    diag = Path(RESUME_FROM) / \"diagnostics.json\"\n",
    "    if diag.exists():\n",
    "        shutil.copy(diag, Path(CKPT_DIR) / \"diagnostics.json\")\n",
    "    print(f\"Warm-started from  : {RESUME_FROM}\")\n",
    "    print(f\"  Copied files     : {list(Path(CKPT_DIR).iterdir())}\")\n",
    "else:\n",
    "    print(\"Starting fresh run (no RESUME_FROM)\")\n",
    "\n",
    "print(f\"Run name           : {RUN_NAME}\")\n",
    "print(f\"Checkpoint dir     : {CKPT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Helper functions (run once after Cell 2)\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# checkpoint_status()    – table of every .pt file across all runs\n",
    "# save_phase(label)      – copy latest.pt → <label>.pt (permanent snapshot)\n",
    "# plot_phase_history()   – loss/accuracy curves for a pretraining history dict\n",
    "\n",
    "import json, shutil, time\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def checkpoint_status(base_dir: str = \"checkpoints\") -> None:\n",
    "    \"\"\"Print a table of all .pt checkpoints across every run.\"\"\"\n",
    "    rows = []\n",
    "    for pt in sorted(Path(base_dir).rglob(\"*.pt\")):\n",
    "        mtime   = pt.stat().st_mtime\n",
    "        size_mb = pt.stat().st_size / 1e6\n",
    "        rows.append((time.strftime(\"%Y-%m-%d %H:%M\", time.localtime(mtime)),\n",
    "                     f\"{size_mb:.1f} MB\", str(pt)))\n",
    "    if rows:\n",
    "        print(f\"{'Modified':<18}  {'Size':<9}  Path\")\n",
    "        print(\"-\" * 72)\n",
    "        for ts, sz, path in rows:\n",
    "            print(f\"{ts:<18}  {sz:<9}  {path}\")\n",
    "    else:\n",
    "        print(f\"No checkpoints found under {base_dir}/\")\n",
    "\n",
    "\n",
    "def save_phase(label: str, ckpt_dir: str = CKPT_DIR) -> None:\n",
    "    \"\"\"Copy latest.pt → <label>.pt for a permanent per-phase snapshot.\"\"\"\n",
    "    src = Path(ckpt_dir) / \"latest.pt\"\n",
    "    if src.exists():\n",
    "        dst = Path(ckpt_dir) / f\"{label}.pt\"\n",
    "        shutil.copy(src, dst)\n",
    "        sz = dst.stat().st_size / 1e6\n",
    "        print(f\"  Saved: {dst}  ({sz:.1f} MB)\")\n",
    "    else:\n",
    "        print(f\"  Warning: {src} not found – nothing saved.\")\n",
    "\n",
    "\n",
    "def plot_phase_history(history: dict, title: str = \"\") -> None:\n",
    "    \"\"\"Plot loss + accuracy curves from a pretrain_* history dict.\"\"\"\n",
    "    has_cursor = \"cursor_losses\" in history and history[\"cursor_losses\"]\n",
    "    ncols = 3 if has_cursor else 2\n",
    "    fig, axes = plt.subplots(1, ncols, figsize=(5 * ncols, 3))\n",
    "\n",
    "    axes[0].plot(history.get(\"tool_losses\", []), color=\"steelblue\")\n",
    "    axes[0].set_title(\"Tool Loss\"); axes[0].set_xlabel(\"Epoch\")\n",
    "\n",
    "    axes[1].plot(history.get(\"tool_accuracies\", []), color=\"green\")\n",
    "    axes[1].set_title(\"Tool Accuracy\"); axes[1].set_xlabel(\"Epoch\")\n",
    "    axes[1].set_ylim(0, 1)\n",
    "\n",
    "    if has_cursor:\n",
    "        axes[2].plot(history[\"cursor_losses\"], color=\"orange\")\n",
    "        axes[2].set_title(\"Cursor Loss\"); axes[2].set_xlabel(\"Epoch\")\n",
    "\n",
    "    if title:\n",
    "        fig.suptitle(title, fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"Helpers loaded: checkpoint_status(), save_phase(), plot_phase_history()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Verify environment\n",
    "import torch\n",
    "print(f\"PyTorch  : {torch.__version__}\")\n",
    "print(f\"CUDA     : {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU      : {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory   : {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "from cadfire.tasks.registry import TaskRegistry\n",
    "TaskRegistry.discover()\n",
    "print(f\"\\nRL tasks ({TaskRegistry.count()}): {TaskRegistry.list_tasks()}\")\n",
    "\n",
    "from cadfire.utils.config import num_tools, tool_list\n",
    "print(f\"Tools ({num_tools()}): {tool_list()[:10]}...\")\n",
    "\n",
    "# Show supervised task count (Phase 2)\n",
    "from cadfire.training.pretrain_semantic import _TASK_REGISTRY\n",
    "total_w = sum(w for w, _, _ in _TASK_REGISTRY)\n",
    "print(f\"\\nPhase-2 supervised tasks: {len(_TASK_REGISTRY)}\")\n",
    "for w, cls, _ in _TASK_REGISTRY:\n",
    "    pct = 100 * w / total_w\n",
    "    print(f\"  {cls.__name__:<28} weight={w:.1f} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Checkpoint browser\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Review what exists BEFORE starting training.\n",
    "# Also shows what the RESUME_FROM run achieved if warm-starting.\n",
    "\n",
    "checkpoint_status()\n",
    "\n",
    "# If warm-starting, peek at the previous run's diagnostics\n",
    "if RESUME_FROM:\n",
    "    diag_path = Path(RESUME_FROM) / \"diagnostics.json\"\n",
    "    if diag_path.exists():\n",
    "        with open(diag_path) as f:\n",
    "            d = json.load(f)\n",
    "        print(f\"\\nPrevious run diagnostics ({RESUME_FROM}):\")\n",
    "        print(f\"  Total RL steps : {d.get('total_steps', 0):,}\")\n",
    "        print(f\"  Total episodes : {d.get('total_episodes', 0):,}\")\n",
    "        print(f\"  Best reward    : {d.get('best_reward', float('-inf')):.4f}\")\n",
    "        if d.get(\"training_log\"):\n",
    "            last = d[\"training_log\"][-1]\n",
    "            print(f\"  Last log entry : {last}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3a: Phase 1 — Tool Classifier Pretraining\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Trains: text encoder + fusion bridge + tool head\n",
    "# Frozen: vision encoder, cursor head (UNet decoder)\n",
    "# Loss:   cross-entropy over (prompt → tool_id) pairs\n",
    "#\n",
    "# Idempotent: loads any existing checkpoint first, trains on top of it.\n",
    "# Raise num_epochs to 50 for ~95%+ accuracy.\n",
    "\n",
    "from train import run_pretrain_tool\n",
    "\n",
    "agent, history1 = run_pretrain_tool(\n",
    "    num_epochs=30,        # ~1 min on GPU; raise to 50 for higher accuracy\n",
    "    lr=1e-3,\n",
    "    batch_size=64,\n",
    "    checkpoint_dir=CKPT_DIR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3a-eval: Post-Phase-1 evaluation + checkpoint snapshot\n",
    "print(f\"Phase 1 final tool accuracy : {history1['tool_accuracies'][-1]:.1%}\")\n",
    "print(f\"Phase 1 final tool loss     : {history1['tool_losses'][-1]:.4f}\")\n",
    "\n",
    "plot_phase_history(history1, title=\"Phase 1 – Tool Classifier\")\n",
    "save_phase(\"phase1_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3b: Phase 2 — Semantic Cursor Pretraining\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Trains:  ALL parameters (vision encoder, text encoder, fusion, tool head,\n",
    "#          cursor head).  Text encoder intentionally unfrozen so the model\n",
    "#          links object names (\"hexagon\", \"circle\") to their visual appearance.\n",
    "# Loss:    cross-entropy tool loss + focal-BCE cursor loss (Gaussian blobs)\n",
    "#\n",
    "# 20 supervised task types (original 11 + SCALE + MIRROR + OFFSET +\n",
    "#   6 multi-turn chat tasks).\n",
    "#\n",
    "# Loads Phase-1 weights from checkpoint if `agent` is not in scope.\n",
    "\n",
    "from train import run_pretrain_semantic\n",
    "\n",
    "agent, history2 = run_pretrain_semantic(\n",
    "    agent=globals().get(\"agent\"),   # reuse Phase-1 agent if it ran above\n",
    "    num_samples=20_000,   # generated samples per epoch; raise to 50_000 for better coverage\n",
    "    num_epochs=20,\n",
    "    lr=3e-4,\n",
    "    batch_size=32,        # keep small — images are 256×256×19\n",
    "    sigma=12.0,           # Gaussian blob radius in pixels\n",
    "    cursor_weight=1.0,    # global scale on cursor-loss term\n",
    "    num_workers=0,        # set to 4 on multi-core instances\n",
    "    checkpoint_dir=CKPT_DIR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3b-eval: Post-Phase-2 evaluation + checkpoint snapshot\n",
    "print(f\"Phase 2 final tool accuracy : {history2['tool_accuracies'][-1]:.1%}\")\n",
    "print(f\"Phase 2 final cursor loss   : {history2['cursor_losses'][-1]:.4f}\")\n",
    "\n",
    "plot_phase_history(history2, title=\"Phase 2 – Semantic Cursor\")\n",
    "save_phase(\"phase2_final\")\n",
    "\n",
    "# Quick sanity: compare Phase 1 vs Phase 2 tool accuracy\n",
    "acc1 = history1[\"tool_accuracies\"][-1]\n",
    "acc2 = history2[\"tool_accuracies\"][-1]\n",
    "delta = acc2 - acc1\n",
    "sign = \"+\" if delta >= 0 else \"\"\n",
    "print(f\"\\nTool accuracy: Phase 1 → Phase 2  ({acc1:.1%} → {acc2:.1%}, {sign}{delta:.1%})\")\n",
    "if delta < -0.05:\n",
    "    print(\"  ⚠ Accuracy dropped >5pp — consider more Phase 1 epochs or a lower Phase 2 LR.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3c: Phase 3 — Teacher-Forced Multi-Step Pretraining\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Trains:  ALL parameters (same as Phase 2)\n",
    "# Method:  at each trajectory step the ORACLE action is executed in the real\n",
    "#          environment; agent loss computed per step — no error accumulation.\n",
    "# Loss:    cross-entropy tool loss + focal-BCE cursor loss, summed over steps\n",
    "#\n",
    "# Trajectory mix:\n",
    "#   70%  polygon-trace  (4–9 POLYLINE clicks + CONFIRM)\n",
    "#   30%  2-step chains  (select→erase, select→rotate, select→copy)\n",
    "#\n",
    "# Loads Phase-2 weights from checkpoint if `agent` is not in scope.\n",
    "\n",
    "from train import run_pretrain_teacher\n",
    "\n",
    "agent, history3 = run_pretrain_teacher(\n",
    "    agent=globals().get(\"agent\"),    # reuse Phase-2 agent if it ran above\n",
    "    num_trajectories=5_000,  # trajectories generated per epoch\n",
    "    num_epochs=15,\n",
    "    lr=1e-4,\n",
    "    sigma=12.0,\n",
    "    cursor_weight=1.5,       # cursor loss weighted higher — sequencing is hard\n",
    "    polygon_ratio=0.7,\n",
    "    checkpoint_dir=CKPT_DIR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3c-eval: Post-Phase-3 evaluation + checkpoint snapshot\n",
    "print(f\"Phase 3 final tool accuracy : {history3['tool_accuracies'][-1]:.1%}\")\n",
    "print(f\"Phase 3 final cursor loss   : {history3['cursor_losses'][-1]:.4f}\")\n",
    "if \"traj_lengths\" in history3:\n",
    "    print(f\"Phase 3 avg traj length     : {history3['traj_lengths'][-1]:.2f} steps\")\n",
    "\n",
    "plot_phase_history(history3, title=\"Phase 3 – Teacher Forcing\")\n",
    "save_phase(\"phase3_final\")\n",
    "\n",
    "# Three-phase summary\n",
    "print(\"\\n── Three-phase tool-accuracy summary ──\")\n",
    "for label, hist in [(\"Phase 1\", history1), (\"Phase 2\", history2), (\"Phase 3\", history3)]:\n",
    "    acc = hist[\"tool_accuracies\"][-1]\n",
    "    print(f\"  {label}: {acc:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3d: Post-Phase-3 Diagnostics — Polygon Tracing GIFs\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Produces two GIF types per episode inside diagnostics/:\n",
    "#   oracle_ep<N>.gif  – oracle-driven rollout with agent heatmap overlay\n",
    "#   free_ep<N>.gif    – fully autonomous agent rollout (no teacher forcing)\n",
    "#\n",
    "# Inspect the free_ep GIFs:\n",
    "#   ✓ Agent traces polygon vertices in order and ends with CONFIRM → ready for RL\n",
    "#   ✗ Agent wanders / repeats a tool → run more Phase 3 epochs before continuing\n",
    "# Requires: pillow (installed in Cell 1)\n",
    "\n",
    "from train import run_diagnostics\n",
    "\n",
    "diag_metrics = run_diagnostics(\n",
    "    agent=globals().get(\"agent\"),\n",
    "    n_episodes=6,\n",
    "    output_dir=f\"{CKPT_DIR}/diagnostics\",\n",
    "    fps=1.5,\n",
    "    checkpoint_dir=CKPT_DIR,\n",
    ")\n",
    "\n",
    "print(\"\\nGenerated GIFs:\")\n",
    "for p in sorted(Path(f\"{CKPT_DIR}/diagnostics\").glob(\"*.gif\")):\n",
    "    print(f\"  {p}\")\n",
    "\n",
    "if diag_metrics:\n",
    "    print(f\"\\nFree-run mean reward  : {diag_metrics.get('mean_free_reward', 0):.3f}\")\n",
    "    print(f\"Oracle mean reward    : {diag_metrics.get('mean_oracle_reward', 0):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3e: Phase 4 — PPO RL Training\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Full agent training with curriculum learning.\n",
    "# Automatically loads from the Phase-3 checkpoint; all prior supervised\n",
    "# learning is preserved.\n",
    "#\n",
    "# Curriculum: difficulty cap starts at 2.0, increases every 5 000 steps.\n",
    "# Checkpoints saved to {CKPT_DIR}/latest.pt and {CKPT_DIR}/best.pt.\n",
    "\n",
    "from train import run_training\n",
    "\n",
    "metrics_history = []\n",
    "def collect_metrics(m):\n",
    "    metrics_history.append(m)\n",
    "\n",
    "trainer = run_training(\n",
    "    num_steps=100_000,\n",
    "    resume=True,           # auto-resume from {CKPT_DIR}/latest.pt\n",
    "    device=None,           # auto-detect GPU\n",
    "    max_difficulty=None,   # curriculum default\n",
    "    checkpoint_dir=CKPT_DIR,\n",
    "    callback=collect_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Plot PPO training progress\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "diag_path = Path(CKPT_DIR) / \"diagnostics.json\"\n",
    "if diag_path.exists():\n",
    "    with open(diag_path) as f:\n",
    "        diag = json.load(f)\n",
    "    log = diag[\"training_log\"]\n",
    "\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 8))\n",
    "    steps = [e[\"step\"] for e in log]\n",
    "\n",
    "    axes[0, 0].plot(steps, [e.get(\"avg_reward\",       0) for e in log])\n",
    "    axes[0, 0].set_title(\"Average Reward\");      axes[0, 0].set_xlabel(\"Step\")\n",
    "\n",
    "    axes[0, 1].plot(steps, [e.get(\"policy_loss\",      0) for e in log])\n",
    "    axes[0, 1].set_title(\"Policy Loss\");         axes[0, 1].set_xlabel(\"Step\")\n",
    "\n",
    "    axes[0, 2].plot(steps, [e.get(\"difficulty\",       0) for e in log])\n",
    "    axes[0, 2].set_title(\"Curriculum Difficulty\"); axes[0, 2].set_xlabel(\"Step\")\n",
    "\n",
    "    axes[1, 0].plot(steps, [e.get(\"value_loss\",       0) for e in log])\n",
    "    axes[1, 0].set_title(\"Value Loss\");          axes[1, 0].set_xlabel(\"Step\")\n",
    "\n",
    "    axes[1, 1].plot(steps, [e.get(\"entropy\",          0) for e in log])\n",
    "    axes[1, 1].set_title(\"Entropy\");             axes[1, 1].set_xlabel(\"Step\")\n",
    "\n",
    "    axes[1, 2].plot(steps, [e.get(\"steps_per_second\", 0) for e in log])\n",
    "    axes[1, 2].set_title(\"Steps/sec\");           axes[1, 2].set_xlabel(\"Step\")\n",
    "\n",
    "    plt.suptitle(f\"PPO — {RUN_NAME}\", fontsize=13)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(Path(CKPT_DIR) / \"training_curves.png\", dpi=100)\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Total steps    : {diag['total_steps']:,}\")\n",
    "    print(f\"Total episodes : {diag['total_episodes']:,}\")\n",
    "    print(f\"Best reward    : {diag['best_reward']:.4f}\")\n",
    "else:\n",
    "    print(f\"No diagnostics.json found in {CKPT_DIR}. Run Phase 4 (Cell 3e) first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Multi-run comparison\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Compare reward curves across multiple training runs on one plot.\n",
    "# Edit RUN_DIRS to select the runs you want to compare.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# ── Edit this list ────────────────────────────────────────────────────────────\n",
    "RUN_DIRS = sorted(Path(\"checkpoints\").glob(\"run_*/\"))  # compare all runs\n",
    "# RUN_DIRS = [\"checkpoints/run_A\", \"checkpoints/run_B\"]  # or pick specific ones\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "found = False\n",
    "\n",
    "for run_dir in RUN_DIRS:\n",
    "    dp = Path(run_dir) / \"diagnostics.json\"\n",
    "    if not dp.exists():\n",
    "        continue\n",
    "    with open(dp) as f:\n",
    "        d = json.load(f)\n",
    "    log = d.get(\"training_log\", [])\n",
    "    if not log:\n",
    "        continue\n",
    "    label = Path(run_dir).name\n",
    "    steps   = [e[\"step\"]             for e in log]\n",
    "    rewards = [e.get(\"avg_reward\", 0) for e in log]\n",
    "    entropy = [e.get(\"entropy\",    0) for e in log]\n",
    "    axes[0].plot(steps, rewards, label=label)\n",
    "    axes[1].plot(steps, entropy, label=label)\n",
    "    found = True\n",
    "\n",
    "if found:\n",
    "    axes[0].set_title(\"Average Reward\");  axes[0].set_xlabel(\"Step\"); axes[0].legend(fontsize=8)\n",
    "    axes[1].set_title(\"Policy Entropy\");  axes[1].set_xlabel(\"Step\"); axes[1].legend(fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No PPO diagnostics found yet. Run Phase 4 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Visualize agent behavior on a specific task\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from cadfire.env.cad_env import CADEnv\n",
    "from cadfire.model.cad_agent import CADAgent\n",
    "from cadfire.renderer.rasterizer import Renderer\n",
    "from cadfire.tasks.registry import TaskRegistry\n",
    "from cadfire.utils.config import load_config\n",
    "\n",
    "config   = load_config()\n",
    "env      = CADEnv(config)\n",
    "renderer = Renderer(config)\n",
    "\n",
    "# Load best checkpoint if it exists, otherwise latest\n",
    "for tag in (\"best\", \"latest\", \"phase3_final\"):\n",
    "    ckpt_path = Path(CKPT_DIR) / f\"{tag}.pt\"\n",
    "    if ckpt_path.exists():\n",
    "        agent_vis = CADAgent.load_checkpoint(str(ckpt_path), config)\n",
    "        print(f\"Loaded: {ckpt_path}\")\n",
    "        break\n",
    "else:\n",
    "    raise FileNotFoundError(f\"No checkpoint found in {CKPT_DIR}\")\n",
    "agent_vis.eval()\n",
    "\n",
    "# ── Change task_name to explore other behaviours ──────────────────────────────\n",
    "TASK_NAME = \"draw_circle\"  # e.g. \"draw_rectangle\", \"select_shape\", \"move_shape\"\n",
    "\n",
    "task = TaskRegistry.create(TASK_NAME, seed=42)\n",
    "obs, info = env.reset(task=task)\n",
    "print(f\"Prompt: {info['prompt']}\")\n",
    "\n",
    "frames = [renderer.render_rgb_only(env.engine)]\n",
    "total_reward = 0\n",
    "\n",
    "for step in range(50):\n",
    "    obs_t = {\n",
    "        \"image\":     torch.tensor(obs[\"image\"]).unsqueeze(0),\n",
    "        \"text_ids\":  torch.tensor(obs[\"text_ids\"], dtype=torch.long).unsqueeze(0),\n",
    "        \"state_vec\": torch.tensor(obs[\"state_vec\"]).unsqueeze(0),\n",
    "    }\n",
    "    action_info = agent_vis.act(obs_t, deterministic=True)\n",
    "    action = {\n",
    "        \"tool_id\": action_info[\"tool_id\"].item(),\n",
    "        \"cursor\":  action_info[\"cursor\"].cpu().numpy()[0],\n",
    "        \"param\":   action_info[\"param\"].item(),\n",
    "    }\n",
    "    obs, reward, term, trunc, info = env.step(action)\n",
    "    total_reward += reward\n",
    "    frames.append(renderer.render_rgb_only(env.engine))\n",
    "    if term or trunc:\n",
    "        break\n",
    "\n",
    "print(f\"Total reward: {total_reward:.3f}, Steps: {step + 1}\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "for ax, idx, title in zip(axes, [0, len(frames) // 2, -1], [\"Start\", \"Middle\", \"End\"]):\n",
    "    ax.imshow(frames[idx])\n",
    "    ax.set_title(title)\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Export drawing to DXF\n",
    "from cadfire.export.dxf_writer import DXFWriter\n",
    "\n",
    "out_path = Path(CKPT_DIR) / \"output.dxf\"\n",
    "writer = DXFWriter()\n",
    "writer.write(env.engine, str(out_path))\n",
    "print(f\"Exported to {out_path}\")\n",
    "print(f\"Entities: {env.engine.entity_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Pull updates + continue training\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# After new tasks, config changes, or bug fixes are pushed:\n",
    "# 1. Pull latest code\n",
    "# 2. (Optional) create a git tag at the current code+checkpoint state\n",
    "# 3. Reload config + re-discover tasks\n",
    "# 4. Resume Phase 4 — handles tool-list growth seamlessly\n",
    "\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Pull\n",
    "r = subprocess.run([\"git\", \"pull\", \"origin\", \"main\"], capture_output=True, text=True)\n",
    "print(r.stdout.strip() or r.stderr.strip())\n",
    "\n",
    "# (Optional) tag this checkpoint state in git for easy rollback\n",
    "# Uncomment the lines below to create a lightweight git tag:\n",
    "# tag_name = f\"ckpt/{RUN_NAME}/step{trainer.total_steps}\"\n",
    "# subprocess.run([\"git\", \"tag\", tag_name], check=True)\n",
    "# print(f\"Git tag created: {tag_name}\")\n",
    "\n",
    "# Reload config + re-discover tasks (picks up any new task files)\n",
    "from cadfire.utils.config import reload\n",
    "reload()\n",
    "from cadfire.tasks.registry import TaskRegistry\n",
    "TaskRegistry.discover()\n",
    "print(f\"\\nTasks after update ({TaskRegistry.count()}): {TaskRegistry.list_tasks()}\")\n",
    "\n",
    "# Continue Phase 4 — auto-resumes, extends tool head if new tools were added\n",
    "from train import run_training\n",
    "trainer = run_training(num_steps=50_000, resume=True, checkpoint_dir=CKPT_DIR)"
   ]
  }
 ]
}
